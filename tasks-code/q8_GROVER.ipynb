{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q8_GROVER",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahpursley/dsci551-assignment2/blob/main/tasks-code/q8_GROVER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MbhMxmizPhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f679853-65d2-4a58-8c87-abb17663804d"
      },
      "source": [
        "#generated emails \n",
        "!cd /content && rm -rf dsci551-assignment2 && git clone https://github.com/sarahpursley/dsci551-assignment2.git\n",
        "import pandas as pd\n",
        "import json \n",
        "import os\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dsci551-assignment2'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (186/186), done.\u001b[K\n",
            "remote: Total 195 (delta 79), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (195/195), 40.71 MiB | 11.70 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUqmlIEBdIj"
      },
      "source": [
        "mal_gen = open('dsci551-assignment2/datasets/generated_text/gpt2_gentext_mal.txt', mode = 'r').readlines()\n",
        "phish_gen = open('dsci551-assignment2/datasets/generated_text/gpt2_gentext_phish.txt', mode = 'r').readlines()\n",
        "recon_gen = open('dsci551-assignment2/datasets/generated_text/gpt2_gentext_recon.txt', mode = 'r').readlines()\n",
        "se_gen = open('dsci551-assignment2/datasets/generated_text/gpt2_gentext_se.txt', mode = 'r').readlines()\n",
        "\n",
        "\n",
        "#using text generated from TTR algorithm for just the fraud message content\n",
        "mal_fraud = open('dsci551-assignment2/datasets/generated_text/m_train.txt', mode = 'r').readlines()\n",
        "se_fraud = open('dsci551-assignment2/datasets/generated_text/s_train.txt', mode = 'r').readlines()\n",
        "recon_fraud = open('dsci551-assignment2/datasets/generated_text/r_train_.txt', mode = 'r').readlines()\n",
        "phish_fraud = open('dsci551-assignment2/datasets/generated_text/p_train.txt', mode = 'r').readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDFe4WJa-nR7"
      },
      "source": [
        "# clean GPU text\n",
        "generated_malware = [line for line in mal_gen if line.rstrip() != ''and line != '====================\\n']\n",
        "generated_phising = [line for line in phish_gen if line.rstrip() != ''and line != '====================\\n']\n",
        "generated_recon = [line for line in recon_gen if line.rstrip() != ''and line != '====================\\n']\n",
        "generated_se = [line for line in se_gen if line.rstrip() != ''and line != '====================\\n']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P2pTmwa9FIS"
      },
      "source": [
        "message_dict = {}\n",
        "index = 0\n",
        "for message in generated_malware:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'malware'}\n",
        "  index+=1\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'malware'}\n",
        "  index+=1\n",
        "\n",
        "for message in generated_phising:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'phishing'}\n",
        "  index+=1\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'phishing'}\n",
        "  index+=1\n",
        "\n",
        "for message in generated_recon:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'reconnaissance'}\n",
        "  index+=1\n",
        "  \n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'reconnaissance'}\n",
        "  index+=1\n",
        "\n",
        "for message in generated_se:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'social_engineering'}\n",
        "  index+=1\n",
        "  \n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'machine', 'email_type':'social_engineering'}\n",
        "  index+=1\n",
        "\n",
        "#real human emails\n",
        "for message in se_fraud:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'human', 'email_type':'social_engineering'}\n",
        "  index+=1\n",
        "\n",
        "for message in mal_fraud:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'human', 'email_type':'malware'}\n",
        "  index+=1\n",
        "\n",
        "for message in recon_fraud:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'human', 'email_type':'reconnaissance'}\n",
        "  index+=1\n",
        "\n",
        "for message in phish_fraud:\n",
        "  message_dict['train_emails_'+ str(index)] = {'email': message, 'label': 'human', 'email_type':'phishing'}\n",
        "  index+=1\n",
        "\n",
        "#example output\n",
        "message_dict['train_emails_0']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVYowO2m_R-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee6d58b-6b83-4b45-93af-14e2d220298d"
      },
      "source": [
        "print(\"There are this many 'lines': \" + str(index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are this many 'lines': 5290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuh_3mE-fxNZ"
      },
      "source": [
        "!cd /content && rm -rf grover && git clone https://github.com/rowanz/grover.git\n",
        "%cd /content/grover\n",
        "\n",
        "!pip install cuda\n",
        "!pip install keras\n",
        "!pip install -r requirements-gpu.txt\n",
        "!python download_model.py base\n",
        "\n",
        "# FOR THE FIRST TIME YOU MUST UNINSTALL AND REINSTALL TENSORFLOW/TENSORFLOW GPU\n",
        "# only do this for the first runtime\n",
        "#!pip uninstall -y tensorflow\n",
        "#!pip install tensorflow-gpu==1.14.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "981L4Dv3okQ0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljj_d3C0ULlu"
      },
      "source": [
        "import json\n",
        "! mkdir input_data\n",
        "\n",
        "all_emails = message_dict\n",
        "\n",
        "with open(\"input_data/train_data.jsonl\", 'w') as f:\n",
        "    for item in all_emails.values():\n",
        "        f.write(json.dumps(item) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IOICTrPzu3J"
      },
      "source": [
        "!export PYTHONPATH=$(pwd)\n",
        "! PYTHONPATH=$(pwd) python lm/train.py --config_file lm/configs/base.json --input_file train_data.jsonl --num_train_steps 10000 --output_dir /content/grover"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcEQ-YNQ2eW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de46efe-43cc-4176-a784-c561f1224709"
      },
      "source": [
        "!export PYTHONPATH=$(pwd)\n",
        "! python lm/train.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"lm/train.py\", line 20, in <module>\n",
            "    from lm.dataloader import input_fn_builder\n",
            "ModuleNotFoundError: No module named 'lm'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUxdznC8bWSG"
      },
      "source": [
        "! mkdir input_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQJnFB1YY5tt",
        "outputId": "9ea1ceb7-0d92-4a00-b81d-09edfba9ae87"
      },
      "source": [
        "!export PYTHONPATH=$(pwd)\n",
        "! PYTHONPATH=$(pwd) python discrimination/run_discrimination.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For discrimination finetuning (e.g. saying whether or not the generation is human/grover)\n",
            "\n",
            "flags:\n",
            "\n",
            "discrimination/run_discrimination.py:\n",
            "  --[no]adafactor: Whether to run adafactor\n",
            "    (default: 'false')\n",
            "  --additional_data: Should we provide additional input data? maybe.\n",
            "  --batch_size: Batch size used\n",
            "    (default: '32')\n",
            "    (an integer)\n",
            "  --config_file: The config json file corresponding to the pre-trained news\n",
            "    model. This specifies the model architecture.\n",
            "    (default: 'configs/base.json')\n",
            "  --[no]do_train: Whether to run training.\n",
            "    (default: 'false')\n",
            "  --gcp_project: [Optional] Project name for the Cloud TPU-enabled project. If\n",
            "    not specified, we will attempt to automatically detect the GCE project from\n",
            "    metadata.\n",
            "  --init_checkpoint: Initial checkpoint (usually from a pre-trained model).\n",
            "  --input_data: The input data dir. Should contain the .tsv files (or other data\n",
            "    files) for the task.\n",
            "  --iterations_per_loop: How many steps to make in each estimator call.\n",
            "    (default: '1000')\n",
            "    (an integer)\n",
            "  --learning_rate: The initial learning rate for Adam.\n",
            "    (default: '5e-05')\n",
            "    (a number)\n",
            "  --master: [Optional] TensorFlow master URL.\n",
            "  --max_seq_length: The maximum total input sequence length after WordPiece\n",
            "    tokenization. Sequences longer than this will be truncated, and sequences\n",
            "    shorter than this will be padded. Must match data generation.\n",
            "    (default: '1024')\n",
            "    (an integer)\n",
            "  --max_training_examples: if you wanna limit the number\n",
            "    (default: '-1')\n",
            "    (an integer)\n",
            "  --num_tpu_cores: Only used if `use_tpu` is True. Total number of TPU cores to\n",
            "    use.\n",
            "    (default: '8')\n",
            "    (an integer)\n",
            "  --num_train_epochs: Total number of training epochs to perform.\n",
            "    (default: '3.0')\n",
            "    (a number)\n",
            "  --output_dir: The output directory where the model checkpoints will be\n",
            "    written.\n",
            "  --[no]predict_test: Whether to run the model in inference mode on the test\n",
            "    set.\n",
            "    (default: 'false')\n",
            "  --[no]predict_val: Whether to run eval on the dev set.\n",
            "    (default: 'false')\n",
            "  --tpu_name: The Cloud TPU to use for training. This should be either the name\n",
            "    used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 url.\n",
            "  --tpu_zone: [Optional] GCE zone where the Cloud TPU is located in. If not\n",
            "    specified, we will attempt to automatically detect the GCE project from\n",
            "    metadata.\n",
            "  --[no]use_tpu: Whether to use TPU or GPU/CPU.\n",
            "    (default: 'false')\n",
            "  --warmup_proportion: Proportion of training to perform linear learning rate\n",
            "    warmup for. E.g., 0.1 = 10% of training.\n",
            "    (default: '0.1')\n",
            "    (a number)\n",
            "\n",
            "Try --helpfull to get a list of all flags.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2UUm8pnqiJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d90721-558b-4d59-b5ba-1f398f09f447"
      },
      "source": [
        "%cd /content/grover\n",
        "!export PYTHONPATH=$(pwd)\n",
        "! PYTHONPATH=$(pwd) python discrimination/run_discrimination.py --input_data input_data/ --init_checkpoint checkpoint --config_file lm/configs/base.json --output_dir content/grover --num_train_epochs 10.0 --do_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/grover\n",
            "EXITING BECAUSE DO_TRAIN IS FALSE AND PATH DOESNT EXIST\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz-VCsBRfNcE"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Someones exampe idk\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJXtxTeWuvUk"
      },
      "source": [
        "`!python discrimination/run_discrimination.py --input_data=./path_to_your_input_data_parent_directory/part8_inputs_total.jsonl --output_dir=gs://YOUR_BUCKET_NAME/outputs --config_file=./path_to_lm_folder_parent_directory/lm/configs/base.json --do_train=True"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}